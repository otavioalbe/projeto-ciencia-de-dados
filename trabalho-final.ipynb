{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final - Coleta, Análise e Preparação de Dados\n",
    "\n",
    "## Grupo: Davi Kniest, João Antonio Hilgert Merck e Otávio De Carli Albuquerque\n",
    "\n",
    "### Descrição do Problema:\n",
    "Compreender quanto o nível de ensino do candidato influencia para se eleger nas eleições municipais do Rio Grande do Sul nos anos de 2012, 2016 e 2020;\n",
    "\n",
    "### Datasets escolhidos:\n",
    "Dados adquiridos a partir do Portal de Dados Oficial do TSE, onde buscamos filtrar por um contexto municipal das votações do Rio Grande do Sul nos anos de 2020, 2016 e 2012;\n",
    "\n",
    "ANO 2020\n",
    "- Resultados: https://dadosabertos.tse.jus.br/dataset/resultados-2020/resource/db0b6c75-dc82-48d8-b207-ba2b420ec58a\n",
    "- Consulta de candidatos: https://dadosabertos.tse.jus.br/dataset/candidatos-2020-subtemas/resource/8187b1aa-5026-4908-a15a-0bf777ee6701\n",
    "\n",
    "ANO 2016\n",
    "- Resultados: https://dadosabertos.tse.jus.br/dataset/resultados-2016/resource/ccd2564b-a576-4c17-a603-31e49f980667\n",
    "- Consulta de candidatos: https://dadosabertos.tse.jus.br/dataset/candidatos-2016/resource/8ecf472b-9caa-4755-9faa-b95bd7aef0d3\n",
    "\n",
    "ANO 2012\n",
    "- Resultados: https://dadosabertos.tse.jus.br/dataset/resultados-2012/resource/01f124d9-d4a0-4e96-9d1c-7be06e63adb2\n",
    "- Consulta de candidatos: https://dadosabertos.tse.jus.br/dataset/candidatos-2012/resource/900bf233-4f13-4e2a-b600-205e4f27986c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados\n",
    "\n",
    "Leitura dos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_consulta = [\n",
    "    './datasets/consulta_cand_2012_RS.csv',\n",
    "    './datasets/consulta_cand_2016_RS.csv',\n",
    "    './datasets/consulta_cand_2020_RS.csv'\n",
    "]\n",
    "\n",
    "caminho_resultado = [\n",
    "    './datasets/votacao_candidato_munzona_2012_RS.csv',\n",
    "    './datasets/votacao_candidato_munzona_2016_RS.csv',\n",
    "    './datasets/votacao_candidato_munzona_2020_RS.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados\n",
    "\n",
    "Remoção de atributos desnecessários para todos ambos datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover_consulta = [\n",
    "    'DT_GERACAO', 'HH_GERACAO', 'NR_TURNO', 'CD_ELEICAO', 'DS_ELEICAO',\n",
    "    'DT_ELEICAO', 'TP_ABRANGENCIA', 'SG_UF', 'NM_URNA_CANDIDATO',\n",
    "    'CD_SITUACAO_CANDIDATO_URNA','NM_TIPO_DESTINACAO_VOTOS','CD_SITUACAO_CANDIDATO_TOT',\n",
    "    'DS_SITUACAO_CANDIDATO_TOT','ST_PREST_CONTAS','ST_SUBSTITUIDO',\n",
    "    'SQ_SUBSTITUIDO','SQ_ORDEM_SUPLENCIA','DT_ACEITE_CANDIDATURA'\n",
    "    'NM_SOCIAL_CANDIDATO', 'NM_EMAIL', 'CD_DETALHE_SITUACAO_CAND',\n",
    "    'DS_DETALHE_SITUACAO_CAND', 'TP_AGREMIACAO', 'NR_CANDIDATO',\n",
    "    'NP_PARTIDO', 'SG_PARTIDO', 'NM_PARTIDO', 'SQ_COLIGACAO', 'NM_TIPO_ELEICAO',\n",
    "    'NM_COLIGACAO', 'DS_COMPOSICAO_COLIGACAO', 'DS_SIT_TOT_TURNO','CD_NACIONALIDADE',\n",
    "    'DS_NACIONALIDADE', 'SG_UF_NASCIMENTO', 'CD_MUNICIPIO_NASCIMENTO',\n",
    "    'NM_MUNICIPIO_NASCIMENTO', 'DT_NASCIMENTO', 'NR_CPF_CANDIDATO', \n",
    "    'NR_IDADE_DATA_POSSE', 'NR_TITULO_ELEITORAL_CANDIDATO', 'CD_GENERO',\n",
    "    'DS_GENERO', 'CD_ESTADO_CIVIL', 'DS_ESTADO_CIVIL', 'CD_COR_RACA',\n",
    "    'DS_COR_RACA', 'CD_SIT_TOT_TURNO', 'VR_DESPESA_MAX_CAMPANHA', 'ST_REELEICAO',\n",
    "    'ST_DECLARAR_BENS', 'NR_PROTOCOLO_CANDIDATURA', 'NR_PROCESSO',\n",
    "    'CD_SITUACAO_CANDIDATO_PLEITO', 'DS_SITUACAO_CANDIDATO_PLEITO',\n",
    "    'CD_SITUACAO_CANDIDADO_URNA', 'DS_SITUACAO_CANDIDATO_URNA',\n",
    "    'ST_CANDIDATO_INSERIDO_URNA', 'NR_PARTIDO', 'NR_FEDERACAO',\n",
    "    'NM_FEDERACAO', 'SG_FEDERACAO','DS_COMPOSICAO_FEDERACAO'\n",
    "]\n",
    "\n",
    "remover_resultado = [\n",
    "    'DT_GERACAO', 'HH_GERACAO', 'NR_TURNO', 'CD_ELEICAO', 'DS_ELEICAO',\n",
    "    'DT_ELEICAO', 'TP_ABRANGENCIA', 'SG_UF', 'SG_UE', 'NM_UE',\n",
    "    'CD_MUNICIPIO', 'NM_MUNICIPIO', 'CD_CARGO', 'DS_CARGO',\n",
    "    'NR_CANDIDATO', 'NM_CANDIDATO', 'NM_URNA', 'NM_SOCIAL_CANDIDATO',\n",
    "    'CD_SITUACAO_CANDIDATURA', 'DS_SITUACAO_CANDIDATURA',\n",
    "    'CD_DETALHE_SITUACAO_CAND', 'DS_DETALHE_SITUACAO_CAND', 'TP_AGREMIACAO',\n",
    "    'NR_PARTIDO', 'SG_PARTIDO', 'NM_PARTIDO', 'SQ_COLIGACAO', 'NM_COLIGACAO',\n",
    "    'DS_COMPOSICAO_COLIGACAO'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo processado e salvo: ./datasets/consulta_cand_2012_RS.csv\n",
      "Arquivo processado e salvo: ./datasets/consulta_cand_2016_RS.csv\n",
      "Arquivo processado e salvo: ./datasets/consulta_cand_2020_RS.csv\n",
      "Arquivo processado e salvo: ./datasets/votacao_candidato_munzona_2012_RS.csv\n",
      "Arquivo processado e salvo: ./datasets/votacao_candidato_munzona_2016_RS.csv\n",
      "Arquivo processado e salvo: ./datasets/votacao_candidato_munzona_2020_RS.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "for caminho_consulta in caminho_consulta:\n",
    "    try:\n",
    "        dataset = pd.read_csv(caminho_consulta, encoding='latin1', sep=';')\n",
    "\n",
    "        dataset_filtrado = dataset.drop(columns=remover_consulta, errors='ignore')\n",
    "\n",
    "        dataset_filtrado.to_csv(\n",
    "            caminho_consulta,\n",
    "            index=False,\n",
    "            sep=';', \n",
    "            encoding='latin1', \n",
    "            quotechar='\"', \n",
    "            quoting=csv.QUOTE_NONNUMERIC \n",
    "        )\n",
    "        print(f\"Arquivo processado e salvo: {caminho_consulta}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o arquivo {caminho_consulta}: {e}\")\n",
    "\n",
    "for caminho_resultado in caminho_resultado:\n",
    "    try:\n",
    "        dataset = pd.read_csv(caminho_resultado, encoding='latin1', sep=';')\n",
    "\n",
    "        dataset_filtrado = dataset.drop(columns=remover_resultado, errors='ignore')\n",
    "\n",
    "        dataset_filtrado.to_csv(\n",
    "            caminho_resultado,\n",
    "            index=False,\n",
    "            sep=';', \n",
    "            encoding='latin1', \n",
    "            quotechar='\"',\n",
    "            quoting=csv.QUOTE_NONNUMERIC\n",
    "        )\n",
    "        print(f\"Arquivo processado e salvo: {caminho_resultado}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o arquivo {caminho_resultado}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integração dos datasets para facilitar a limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao consolidar arquivos: [Errno 13] Permission denied: '.'\n",
      "Erro ao consolidar arquivos: [Errno 13] Permission denied: '.'\n"
     ]
    }
   ],
   "source": [
    "def unir_arquivos(lista_caminhos, arquivo_saida):\n",
    "    try:\n",
    "        dfs = []\n",
    "        \n",
    "        for caminho in lista_caminhos:\n",
    "            df = pd.read_csv(caminho, encoding='latin1', sep=';')\n",
    "            dfs.append(df)\n",
    "\n",
    "        df_unido = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "        df_unido.to_csv(arquivo_saida, index=False, sep=';', encoding='latin1', quotechar='\"', quoting=1)\n",
    "        print(f\"Arquivo consolidado salvo em: {arquivo_saida}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao consolidar arquivos: {e}\")\n",
    "\n",
    "unir_arquivos(caminho_consulta, './datasets/consulta_cand_RS.csv')\n",
    "unir_arquivos(caminho_resultado, './datasets/votacao_cand_RS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza e integração de dados do dataset 'votacao_candidato'\n",
    "\n",
    "* Limpeza de duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao remover duplicatas do arquivo ./datasets/votacao_cand_RS.csv: [Errno 2] No such file or directory: './datasets/votacao_cand_RS.csv'\n"
     ]
    }
   ],
   "source": [
    "votacao_candidato_path = './datasets/votacao_cand_RS.csv'\n",
    "\n",
    "def remover_duplicatas(caminho_entrada, caminho_saida):\n",
    "    try:\n",
    "        df = pd.read_csv(caminho_entrada, encoding='latin1', sep=';')\n",
    "        \n",
    "        df_sem_duplicatas = df.drop_duplicates()\n",
    "        \n",
    "        df_sem_duplicatas.to_csv(caminho_saida, index=False, sep=';', encoding='latin1', quotechar='\"', quoting=1)\n",
    "        \n",
    "        print(f\"Arquivo sem duplicatas salvo em: {caminho_saida}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao remover duplicatas do arquivo {caminho_entrada}: {e}\")\n",
    "\n",
    "remover_duplicatas(votacao_candidato_path, './datasets/votacao_cand_RS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtragem por apenas Eleição Ordinária\n",
    "* Remoção dos atributos: CD_TIPO_ELEICAO, NM_TIPO_ELEICAO, NR_ZONA e ST_VOTO_EM_TRANSITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao filtrar e processar o arquivo: [Errno 2] No such file or directory: './datasets/votacao_cand_RS.csv'\n"
     ]
    }
   ],
   "source": [
    "colunas_remover = ['CD_TIPO_ELEICAO', 'NM_TIPO_ELEICAO', 'NR_ZONA', 'ST_VOTO_EM_TRANSITO']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(votacao_candidato_path, encoding='latin1', sep=';')\n",
    "    \n",
    "    df_filtrado = df[df['CD_TIPO_ELEICAO'] == 2]\n",
    "\n",
    "    df_filtrado = df_filtrado.drop(columns=colunas_remover, errors='ignore')\n",
    "    \n",
    "    df_filtrado.to_csv(votacao_candidato_path, index=False, sep=';', encoding='latin1', quotechar='\"', quoting=1)\n",
    "    \n",
    "    print(f\"Arquivo filtrado salvo em: {votacao_candidato_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao filtrar e processar o arquivo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sendo o ID composto por ANO_ELEICAO + SQ_CANDIDATO, somar os votos e criar um novo atributo: VOTOS_TOTAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao consolidar os votos: [Errno 2] No such file or directory: './datasets/votacao_cand_RS.csv'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(votacao_candidato_path, encoding='latin1', sep=';')\n",
    "    \n",
    "    df['ID'] = df['ANO_ELEICAO'].astype(str) + '_' + df['SQ_CANDIDATO'].astype(str)\n",
    "    \n",
    "    df_agrupado = df.groupby('ID', as_index=False).agg({\n",
    "        'ANO_ELEICAO': 'first',\n",
    "        'SQ_CANDIDATO': 'first',\n",
    "        'QT_VOTOS_NOMINAIS': 'sum'\n",
    "    })\n",
    "    \n",
    "    df_agrupado = df_agrupado.rename(columns={'QT_VOTOS_NOMINAIS': 'VOTOS_TOTAIS'})\n",
    "    \n",
    "    df_agrupado.to_csv(votacao_candidato_path, index=False, sep=';', encoding='latin1', quotechar='\"', quoting=1)\n",
    "    \n",
    "    print(f\"Arquivo consolidado com VOTOS_TOTAIS salvo em: {votacao_candidato_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao consolidar os votos: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza e integração de dados do dataset 'consulta_cand'\n",
    "\n",
    "* Limpeza de duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao remover duplicatas do arquivo ./datasets/consulta_cand_RS.csv: [Errno 2] No such file or directory: './datasets/consulta_cand_RS.csv'\n"
     ]
    }
   ],
   "source": [
    "consulta_cand_path = './datasets/consulta_cand_RS.csv'\n",
    "\n",
    "def remover_duplicatas(caminho_entrada, caminho_saida):\n",
    "    try:\n",
    "        df = pd.read_csv(caminho_entrada, encoding='latin1', sep=';')\n",
    "        \n",
    "        df_sem_duplicatas = df.drop_duplicates()\n",
    "        \n",
    "        df_sem_duplicatas.to_csv(caminho_saida, index=False, sep=';', encoding='latin1', quotechar='\"', quoting=1)\n",
    "        \n",
    "        print(f\"Arquivo sem duplicatas salvo em: {caminho_saida}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao remover duplicatas do arquivo {caminho_entrada}: {e}\")\n",
    "\n",
    "remover_duplicatas(consulta_cand_path, './datasets/votacao_cand_RS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* União das zonas eleitorais e remoção de SG_UE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao consolidar o arquivo consulta_candidatos: [Errno 2] No such file or directory: './datasets/consulta_cand_RS.csv'\n"
     ]
    }
   ],
   "source": [
    "colunas_remover = ['SG_UE']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(consulta_cand_path, encoding='latin1', sep=';')\n",
    "    \n",
    "    df['ID'] = df['ANO_ELEICAO'].astype(str) + '_' + df['SQ_CANDIDATO'].astype(str)\n",
    "    \n",
    "    df_agrupado = df.groupby('ID', as_index=False).first()\n",
    "    \n",
    "    df_agrupado = df_agrupado.drop(columns=colunas_remover, errors='ignore')\n",
    "    \n",
    "    df_agrupado.to_csv(consulta_cand_path, index=False, sep=';', encoding='latin1', quotechar='\"', quoting=1)\n",
    "    \n",
    "    print(f\"Arquivo consolidado por cidade salvo em: {consulta_cand_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao consolidar o arquivo consulta_candidatos: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Agrupamento por 'CD_SITUACAO_CANDIDATURA' = 2, significando candidato APTO para se eleger\n",
    "* Após agrupamento, remoção dos atributos 'CD_SITUACAO_CANDIDATURA' e 'DS_SITUACAO_CANDIDATURA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao filtrar e consolidar o arquivo consulta_candidatos: [Errno 2] No such file or directory: './datasets/consulta_cand_RS.csv'\n"
     ]
    }
   ],
   "source": [
    "colunas_remover = ['CD_SITUACAO_CANDIDATURA', 'DS_SITUACAO_CANDIDATURA', 'CD_TIPO_ELEICAO']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(consulta_cand_path, encoding='latin1', sep=';')\n",
    "    \n",
    "    df_filtrado = df[(df['CD_SITUACAO_CANDIDATURA'] == 12) & (df['CD_TIPO_ELEICAO'] == 2)]\n",
    "    \n",
    "    df_filtrado['ID'] = df_filtrado['ANO_ELEICAO'].astype(str) + '_' + df_filtrado['SQ_CANDIDATO'].astype(str)\n",
    "    \n",
    "    df_agrupado = df_filtrado.drop(columns=colunas_remover, errors='ignore')\n",
    "    \n",
    "    df_agrupado.to_csv(consulta_cand_path, index=False, sep=';', encoding='latin1', quotechar='\"', quoting=1)\n",
    "    \n",
    "    print(f\"Arquivo filtrado e consolidado por cidade salvo em: {consulta_cand_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao filtrar e consolidar o arquivo consulta_candidatos: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
